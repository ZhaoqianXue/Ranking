"method","theta_hat","rank","ci_two_left","ci_two_right","ci_left","ci_uniform_left"
"calme-3.2-instruct-78b",1.20991101962732,2,1,10,1,1
"calme-3.1-instruct-78b",1.10170544991881,4,1,16,1,1
"CalmeRys-78B-Orpo-v0.1",1.21256485011465,1,1,9,1,1
"calme-2.4-rys-78b",1.1216450809047,3,1,15,1,1
"Qwen2.5-72B-Instruct-abli...6",0.797439196268625,9,1,27,3,1
"Qwen2.5-72B-Instruct",0.693119825803686,15,3,33,4,1
"calme-2.1-qwen2.5-72b",0.616126305177695,19,5,35,5,3
"Homer-v1.0-Qwen2.5-72B",0.882700087787014,6,1,23,1,1
"qwen2.5-test-32b-it",0.575186738231908,20,5,39,6,3
"Linkbricks-Horizon-AI-Ave...11",0.515936365631034,21,6,42,6,5
"calme-2.2-qwen2.5-72b",0.413638936770712,25,8,49,8,6
"FluentlyLM-Prinum",0.749436679618124,10,3,29,3,1
"T3Q-qwen2.5-14b-v1.0-e3",0.745888448252018,11,3,29,3,1
"T3Q-Qwen2.5-14B-Instruct-",0.803875705902367,8,1,27,1,1
"Qwen2.5-32B-Instruct-abli",0.302236350536932,30,13,56,15,7
"Gilgamesh-72B",0.86793356372506,7,1,23,1,1
"ultiima-72B",0.738611871040388,12,3,29,3,1
"zetasepic-abliteratedV2-Q",0.332292332697784,29,10,55,14,6
"Awqward2.5-32B-Instruct",0.277897446114885,33,15,56,16,8
"test-2.5-72B",1.00609394499478,5,1,19,1,1
"shuttle-3",0.703529153764177,14,3,33,3,1
"Qwen2.5-32B-Instruct",0.124776367369881,41,21,67,22,16
"Mistral-Large-Instruct-24",0.457474822810641,22,6,48,8,5
"Rombos-LLM-V2.5-Qwen-72b",0.731528574894676,13,3,29,3,1
"Linkbricks-Horizon-AI-Ave...26",0.0747882046671715,46,22,71,22,19
"Qwen2.5-72B-Instruct-abli...27",0.653844477176441,17,4,34,5,1
"Linkbricks-Horizon-AI-Ave...28",0.0377818261902738,48,22,73,25,20
"lambda-qwen2.5-32b-dpo-te",-0.0556962054364005,54,28,75,30,22
"Qwentile2.5-32B-Instruct",0.358076438478974,28,10,54,10,6
"Rombos-LLM-V2.5-Qwen-32b",0.645496788048233,18,5,35,5,1
"openbuddy-llama3.3-70b-v2",0.294142460539737,31,14,56,16,8
"Linkbricks-Horizon-AI-Ave...33",0.168640418146473,38,20,64,21,14
"huihui-ai-abliterated-Qwe",-0.0739396120095819,55,29,75,30,22
"Linkbricks-Horizon-AI-Ave...35",0.084105656265919,44,22,69,22,19
"ultiima-32B",0.448462966906278,23,7,48,8,5
"RYS-XLarge",0.287391602874786,32,14,56,16,8
"Qwen2.5-95B-Instruct",-0.0316853241231652,51,27,75,28,21
"ultiima-72B-v1.5",0.661885360228146,16,4,34,5,1
"sky-t1-coder-32b-flash",-0.188526982968324,60,34,82,36,28
"Llama-3.3-70B-Instruct",-0.246762404367858,64,36,87,40,30
"RomboUltima-32B",0.162230516143415,39,20,64,21,14
"calme-2.1-rys-78b",0.231493987341387,34,18,59,19,10
"calme-2.3-rys-78b",0.222998251526089,35,18,60,20,10
"calme-2.1-qwen2-72b",0.115203755453356,42,21,68,22,16
"calme-2.2-rys-78b",0.09079155343121,43,22,69,22,18
"MG-FinalMix-72B",0.0524406879539296,47,22,73,24,20
"EVA-Qwen2.5-72B-v0.2",0.423077018426058,24,8,48,8,6
"Qwen2-72B-Orpo-v0.1",-0.00256192306584158,49,26,74,28,21
"RYS-XLarge-base",-0.0206193966536112,50,27,74,28,21
"calme-2.2-qwen2-72b",-0.225704596995183,62,36,82,40,30
"Arcee-Nova",-0.153199462079124,58,34,79,34,26
"L3.3-MS-Nevoria-70b",-0.0497984643871043,53,28,75,30,22
"Set-70b",-0.0429517192315618,52,28,75,29,22
"QwentileSwap",0.174033064783457,37,20,64,21,13
"li-14b-v0.4",-0.538045580563194,77,56,100,57,49
"tempmotacilla-cinerea-030",-0.549766714696753,78,57,100,57,49
"L3.3-Nevoria-R1-70b",0.0763856494176984,45,22,71,23,19
"Qwen2-72B-Instruct",-0.263127466922671,65,40,87,42,31
"Galactic-Qwen-14B-Exp2",0.179801902299994,36,20,63,21,12
"BigQwen2.5-52B-Instruct",-0.280535506966561,67,41,90,43,34
"Llama-3.1-SauerkrautLM-70",-0.166487151614724,59,34,80,36,27
"Llama-3.1-70B-Instruct",-0.340977537880281,70,47,93,48,36
"Dracarys-72B-Instruct",-0.346555028446524,71,47,93,49,36
"Linkbricks-Horizon-AI-Ave...65",-0.2047543383218,61,36,82,37,29
"Lamarckvergence-14B",-0.615325755080148,82,60,100,62,53
"Lix-14B-v0.1",-0.678842104682888,86,64,100,67,56
"calme-2.2-llama3.1-70b",-0.361676434501802,72,47,94,49,36
"NQLSG-Qwen2.5-14B-MegaFus...69",-0.594948466203804,80,59,100,61,51
"calme-2.3-llama3.1-70b",-0.372348648942923,73,47,94,49,36
"NQLSG-Qwen2.5-14B-MegaFus...71",-0.76951203837318,93,70,100,72,60
"orca_mini_v8_1_70b",-0.237141074044737,63,36,87,40,30
"Apollo-70B",0.146888298172879,40,21,67,21,14
"ZYH-LLM-Qwen2.5-14B-V4",-0.536727619001439,76,56,100,57,49
"NQLSG-Qwen2.5-14B-MegaFus...75",-0.789625070272281,94,71,100,74,62
"Progenitor-V1.1-LLaMa-70B",-0.153171809790682,57,34,79,34,26
"70B-L3.3-Cirrus-x1",-0.108029018419226,56,30,77,34,24
"magnum-v1-72b",-0.317159412968347,69,43,90,47,34
"magnum-72b-v1",-0.301130393866322,68,43,90,45,34
"lamarckvergence-14b-tenso",-0.762083237865019,91,70,100,72,60
"li-14b-v0.4-slerp0.1",-0.85457185469318,99,74,100,75,66
"miscii-14b-0218",-0.69745636828928,88,65,100,68,57
"Cheng-2",-0.664836690278539,83,62,100,65,56
"NQLSG-Qwen2.5-14B-MegaFus...84",-0.837402188096626,96,74,100,75,65
"Llama3.3-70B-CogniLink",-0.267673912914867,66,39,90,41,32
"tempesthenno-ppo-ckpt40",-0.676329514156744,85,64,100,68,56
"RYS-Llama3.1-Large",-0.450908916938254,75,51,99,55,43
"virtuoso-small-v2-tensopo",-0.550422467340911,79,57,100,57,49
"Cheng-2-v1.1",-0.76778380579597,92,69,100,70,60
"RombosBeagle-v2beta-MGS-3",0.400930749605956,26,8,50,10,6
"TheBeagle-v2beta-32B-MGS",0.38386183146919,27,8,50,10,6
"lambda-qwen2.5-14b-dpo-te",-0.609151236436252,81,59,100,61,52
"tempesthenno-nuslerp-001",-0.703364057363418,89,66,100,69,57
"Qwen2.5-14B-1M-YOYO-V3",-0.821179819799406,95,73,100,74,63
"Josiefied-Qwen2.5-14B-Ins",-0.685227500086185,87,64,100,67,57
"NQLSG-Qwen2.5-14B-MegaFus...96",-0.906729719952462,100,75,100,76,69
"Q2.5-Veltha-14B",-0.714618904962612,90,67,100,69,57
"ECE-ILAB-Q1",-0.410410671211056,74,49,98,52,40
"Virtuoso-Small-v2",-0.67279302109968,84,63,100,65,56
"Qwen2.5-14B-YOYO-V4-p1",-0.848383309448862,98,74,100,75,65
"Chocolatine-14B-Instruct-",-0.837642123897576,97,74,100,75,65
